{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo de Fin de Grado: Aplicación de Inteligencia artificial a la predicción de los efectos de la radiación en sistemas digitales complejos\n",
    "\n",
    "### Pablo Darós Pallarés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = pd.read_csv('radecs_one_hot_label.csv', delimiter=\",\")\n",
    "\n",
    "df_unique_label = pd.read_csv('radecs_unique_label.csv', delimiter=\",\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera la X e Y para entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para comprobar si los valores de SEE son lists o str\n",
    "def parse_see_value(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return eval(value)\n",
    "        except:\n",
    "            return [value] \n",
    "    elif isinstance(value, list):\n",
    "        return value\n",
    "    else:\n",
    "        return [value]\n",
    "\n",
    "# Se comprueba si SEE es un list o str\n",
    "df_unique_label['SEE'] = df_unique_label['SEE'].apply(parse_see_value)\n",
    "\n",
    "# Convertir SEE para un modelo multietiqueta\n",
    "mlb = MultiLabelBinarizer()\n",
    "see_encoded = mlb.fit_transform(df_unique_label['SEE'])\n",
    "\n",
    "# Se añaden las nuevas columnas al df\n",
    "see_encoded_df = pd.DataFrame(see_encoded, columns=mlb.classes_, index=df_unique_label.index)\n",
    "df_unique_label = pd.concat([df_unique_label, see_encoded_df], axis=1)\n",
    "\n",
    "# Eliminar la columna original\n",
    "df_unique_label.drop('SEE', axis=1, inplace=True)\n",
    "\n",
    "# Se convierten las columnas categóricas a numéricas\n",
    "categorical_cols = df_unique_label.select_dtypes(include=['object']).columns\n",
    "df_unique_label = pd.get_dummies(df_unique_label, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Se eliminan carácteres especiales\n",
    "df_unique_label.columns = df_unique_label.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Asegurar que cada columna tiene un nombre unico\n",
    "def make_unique(column_names):\n",
    "    seen = {}\n",
    "    for i, name in enumerate(column_names):\n",
    "        if name in seen:\n",
    "            seen[name] += 1\n",
    "            new_name = f\"{name}_{seen[name]}\"\n",
    "            while new_name in seen:\n",
    "                seen[name] += 1\n",
    "                new_name = f\"{name}_{seen[name]}\"\n",
    "            column_names[i] = new_name\n",
    "        else:\n",
    "            seen[name] = 1\n",
    "    return column_names\n",
    "\n",
    "df_unique_label.columns = make_unique(list(df_unique_label.columns))\n",
    "\n",
    "# Se formatean correctamente los nombres de las clases\n",
    "class_names = [name.replace(':', '').replace(',', '') for name in mlb.classes_]\n",
    "\n",
    "# Comentar estas lineas si se desean obtener los resultados originales ----------\n",
    "# Se eliminan estas 7 etiquetas debido a ser demasiado infrecuentes\n",
    "removed_labels = ['SEUAlpha', 'SEUPAlpha', 'SEUPNAlpha', 'SEUe', 'SETLP', 'SEFIHPL', 'SEGRN']\n",
    "class_names = [name for name in class_names if name not in removed_labels]\n",
    "# ----------\n",
    "\n",
    "# Se crean X e Y\n",
    "X = df_unique_label.drop(columns=class_names, axis=1)\n",
    "y = df_unique_label[class_names].values\n",
    "\n",
    "# Se divide en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Se crea la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_params = {\n",
    "    'estimator__n_estimators': [50, 100],\n",
    "    'estimator__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "rf_clf = OneVsRestClassifier(rf_model)\n",
    "rf_grid_search = GridSearchCV(rf_clf, rf_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "rf_y_pred = rf_best_model.predict(X_test)\n",
    "rf_report = classification_report(y_test, rf_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"Mejores hiperparámetros: {rf_grid_search.best_params_}\")\n",
    "print(rf_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_params = {\n",
    "    'estimator__n_estimators': [50, 100],\n",
    "    'estimator__learning_rate': [0.1, 0.01],\n",
    "    'estimator__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "gb_clf = OneVsRestClassifier(gb_model)\n",
    "gb_grid_search = GridSearchCV(gb_clf, gb_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "gb_best_model = gb_grid_search.best_estimator_\n",
    "gb_y_pred = gb_best_model.predict(X_test)\n",
    "gb_report = classification_report(y_test, gb_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"Gradient Boosting\")\n",
    "print(f\"Mejores hiperparámetros: {gb_grid_search.best_params_}\")\n",
    "print(gb_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "svm_model = SVC(probability=True)\n",
    "svm_params = {\n",
    "    'estimator__C': [0.1, 1, 10],\n",
    "    'estimator__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "svm_clf = OneVsRestClassifier(svm_model)\n",
    "svm_grid_search = GridSearchCV(svm_clf, svm_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "svm_best_model = svm_grid_search.best_estimator_\n",
    "svm_y_pred = svm_best_model.predict(X_test)\n",
    "svm_report = classification_report(y_test, svm_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"SVM (Linear)\")\n",
    "print(f\"Mejores hiperparámetros: {svm_grid_search.best_params_}\")\n",
    "print(svm_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "mlp_params = {\n",
    "    'estimator__hidden_layer_sizes': [(50,), (100,)],\n",
    "    'estimator__alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "mlp_clf = OneVsRestClassifier(mlp_model)\n",
    "mlp_grid_search = GridSearchCV(mlp_clf, mlp_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "mlp_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "mlp_best_model = mlp_grid_search.best_estimator_\n",
    "mlp_y_pred = mlp_best_model.predict(X_test)\n",
    "mlp_report = classification_report(y_test, mlp_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"MLP Classifier\")\n",
    "print(f\"Mejores hiperparámetros: {mlp_grid_search.best_params_}\")\n",
    "print(mlp_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'estimator__n_neighbors': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "knn_clf = OneVsRestClassifier(knn_model)\n",
    "knn_grid_search = GridSearchCV(knn_clf, knn_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "knn_best_model = knn_grid_search.best_estimator_\n",
    "knn_y_pred = knn_best_model.predict(X_test)\n",
    "knn_report = classification_report(y_test, knn_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(f\"Mejores hiperparámetros: {knn_grid_search.best_params_}\")\n",
    "print(knn_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_params = {\n",
    "    'estimator__n_estimators': [50, 100],\n",
    "    'estimator__learning_rate': [0.1, 0.01],\n",
    "    'estimator__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "xgb_clf = OneVsRestClassifier(xgb_model)\n",
    "xgb_grid_search = GridSearchCV(xgb_clf, xgb_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "xgb_best_model = xgb_grid_search.best_estimator_\n",
    "xgb_y_pred = xgb_best_model.predict(X_test)\n",
    "xgb_report = classification_report(y_test, xgb_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(f\"Mejores hiperparámetros: {xgb_grid_search.best_params_}\")\n",
    "print(xgb_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_params = {\n",
    "    'estimator__n_estimators': [50, 100],\n",
    "    'estimator__learning_rate': [0.1, 0.01],\n",
    "    'estimator__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "lgb_clf = OneVsRestClassifier(lgb_model)\n",
    "lgb_grid_search = GridSearchCV(lgb_clf, lgb_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "lgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "lgb_best_model = lgb_grid_search.best_estimator_\n",
    "lgb_y_pred = lgb_best_model.predict(X_test)\n",
    "lgb_report = classification_report(y_test, lgb_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"LightGBM\")\n",
    "print(f\"Mejores hiperparámetros: {lgb_grid_search.best_params_}\")\n",
    "print(lgb_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización de hiperparámetros\n",
    "cat_model = CatBoostClassifier(verbose=0)\n",
    "cat_params = {\n",
    "    'estimator__iterations': [100, 200],\n",
    "    'estimator__learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "cat_clf = OneVsRestClassifier(cat_model)\n",
    "cat_grid_search = GridSearchCV(cat_clf, cat_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "cat_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "cat_best_model = cat_grid_search.best_estimator_\n",
    "cat_y_pred = cat_best_model.predict(X_test)\n",
    "cat_report = classification_report(y_test, cat_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"CatBoost\")\n",
    "print(f\"Mejores hiperparámetros: {cat_grid_search.best_params_}\")\n",
    "print(cat_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
