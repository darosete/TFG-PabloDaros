{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo de Fin de Grado: Aplicación de Inteligencia artificial a la predicción de los efectos de la radiación en sistemas digitales complejos\n",
    "\n",
    "### Pablo Darós Pallarés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se busca optimizar los modelos MLP. Para ello se prueban alternativas para reducir la dimensionalidad:\n",
    "- SelectFromModel\n",
    "- Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, learning_curve\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df_one_hot = pd.read_csv('data/radecs_one_hot_label.csv', delimiter=\",\")\n",
    "df_unique_label = pd.read_csv('data/radecs_unique_label.csv', delimiter=\",\")\n",
    "\n",
    "# Funcion para comprobar si los valores de SEE son lists o str\n",
    "def parse_see_value(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return eval(value)\n",
    "        except:\n",
    "            return [value]  # Caso en que el eval no sea necesario\n",
    "    elif isinstance(value, list):\n",
    "        return value\n",
    "    else:\n",
    "        return [value]\n",
    "\n",
    "# Se comprueba si SEE es un list o str\n",
    "df_unique_label['SEE'] = df_unique_label['SEE'].apply(parse_see_value)\n",
    "\n",
    "# Convertir SEE para un modelo multietiqueta\n",
    "mlb = MultiLabelBinarizer()\n",
    "see_encoded = mlb.fit_transform(df_unique_label['SEE'])\n",
    "\n",
    "# Se añaden las nuevas columnas al df\n",
    "see_encoded_df = pd.DataFrame(see_encoded, columns=mlb.classes_, index=df_unique_label.index)\n",
    "df_unique_label = pd.concat([df_unique_label, see_encoded_df], axis=1)\n",
    "\n",
    "# Eliminar la columna original\n",
    "df_unique_label.drop('SEE', axis=1, inplace=True)\n",
    "\n",
    "# Se convierten las columnas categóricas a numéricas\n",
    "categorical_cols = df_unique_label.select_dtypes(include=['object']).columns\n",
    "df_unique_label = pd.get_dummies(df_unique_label, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Se eliminan carácteres especiales\n",
    "df_unique_label.columns = df_unique_label.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Asegurar que cada columna tiene un nombre unico\n",
    "def make_unique(column_names):\n",
    "    seen = {}\n",
    "    for i, name in enumerate(column_names):\n",
    "        if name in seen:\n",
    "            seen[name] += 1\n",
    "            new_name = f\"{name}_{seen[name]}\"\n",
    "            while new_name in seen:\n",
    "                seen[name] += 1\n",
    "                new_name = f\"{name}_{seen[name]}\"\n",
    "            column_names[i] = new_name\n",
    "        else:\n",
    "            seen[name] = 1\n",
    "    return column_names\n",
    "\n",
    "df_unique_label.columns = make_unique(list(df_unique_label.columns))\n",
    "\n",
    "# Se formatean correctamente los nombres de las clases\n",
    "class_names = [name.replace(':', '').replace(',', '') for name in mlb.classes_]\n",
    "\n",
    "# Se eliminan estas 7 etiquetas debido a ser demasiado infrecuentes\n",
    "removed_labels = ['SEUAlpha', 'SEUPAlpha', 'SEUPNAlpha', 'SEUe', 'SETLP', 'SEFIHPL', 'SEGRN']\n",
    "class_names = [name for name in class_names if name not in removed_labels]\n",
    "\n",
    "# Se crean X e Y\n",
    "X = df_unique_label.drop(columns=class_names, axis=1)\n",
    "y = df_unique_label[class_names].values\n",
    "\n",
    "# Se buscan las características más relevantees con SelectFromModel\n",
    "selected_features = np.zeros(X.shape[1], dtype=bool)\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    selector = SelectFromModel(estimator=LogisticRegression(solver='liblinear'), threshold=\"median\").fit(X, y[:, i])\n",
    "    selected_features = np.logical_or(selected_features, selector.get_support())\n",
    "\n",
    "X_new = X.loc[:, selected_features]\n",
    "\n",
    "# Se divide en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Se crea la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Se crea el modelo\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "\n",
    "# Hiper parametros\n",
    "mlp_params = {\n",
    "    'estimator__hidden_layer_sizes': [(50,)],  # Menos configuraciones de capas\n",
    "    'estimator__alpha': [0.0001]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "mlp_clf = OneVsRestClassifier(mlp_model)\n",
    "mlp_grid_search = GridSearchCV(mlp_clf, mlp_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "mlp_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "mlp_best_model = mlp_grid_search.best_estimator_\n",
    "mlp_y_pred = mlp_best_model.predict(X_test)\n",
    "mlp_report = classification_report(y_test, mlp_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"MLP Classifier\")\n",
    "print(f\"Mejores hiperparámetros: {mlp_grid_search.best_params_}\")\n",
    "print(mlp_report)\n",
    "\n",
    "##################\n",
    "# Codigo para crear las curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(mlp_best_model, X_train, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "# Se calcula la media y la desv. estándar\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Se generan los graficos\n",
    "plt.figure()\n",
    "plt.title(\"Curva de Aprendizaje - MLP Classifier\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "# Se dibujan las rectas\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df_one_hot = pd.read_csv('data/radecs_one_hot_label.csv', delimiter=\",\")\n",
    "df_unique_label = pd.read_csv('data/radecs_unique_label.csv', delimiter=\",\")\n",
    "\n",
    "# Funcion para comprobar si los valores de SEE son lists o str\n",
    "def parse_see_value(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return eval(value)\n",
    "        except:\n",
    "            return [value]  # Caso en que el eval no sea necesario\n",
    "    elif isinstance(value, list):\n",
    "        return value\n",
    "    else:\n",
    "        return [value]\n",
    "\n",
    "# Se comprueba si SEE es un list o str\n",
    "df_unique_label['SEE'] = df_unique_label['SEE'].apply(parse_see_value)\n",
    "\n",
    "# Convertir SEE para un modelo multietiqueta\n",
    "mlb = MultiLabelBinarizer()\n",
    "see_encoded = mlb.fit_transform(df_unique_label['SEE'])\n",
    "\n",
    "# Se añaden las nuevas columnas al df\n",
    "see_encoded_df = pd.DataFrame(see_encoded, columns=mlb.classes_, index=df_unique_label.index)\n",
    "df_unique_label = pd.concat([df_unique_label, see_encoded_df], axis=1)\n",
    "\n",
    "# Eliminar la columna original\n",
    "df_unique_label.drop('SEE', axis=1, inplace=True)\n",
    "\n",
    "# Se convierten las columnas categóricas a numéricas\n",
    "categorical_cols = df_unique_label.select_dtypes(include=['object']).columns\n",
    "df_unique_label = pd.get_dummies(df_unique_label, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Se eliminan carácteres especiales\n",
    "df_unique_label.columns = df_unique_label.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Asegurar que cada columna tiene un nombre unico\n",
    "def make_unique(column_names):\n",
    "    seen = {}\n",
    "    for i, name in enumerate(column_names):\n",
    "        if name in seen:\n",
    "            seen[name] += 1\n",
    "            new_name = f\"{name}_{seen[name]}\"\n",
    "            while new_name in seen:\n",
    "                seen[name] += 1\n",
    "                new_name = f\"{name}_{seen[name]}\"\n",
    "            column_names[i] = new_name\n",
    "        else:\n",
    "            seen[name] = 1\n",
    "    return column_names\n",
    "\n",
    "df_unique_label.columns = make_unique(list(df_unique_label.columns))\n",
    "\n",
    "# Se formatean correctamente los nombres de las clases\n",
    "class_names = [name.replace(':', '').replace(',', '') for name in mlb.classes_]\n",
    "\n",
    "# Se eliminan estas 7 etiquetas debido a ser demasiado infrecuentes\n",
    "removed_labels = ['SEUAlpha', 'SEUPAlpha', 'SEUPNAlpha', 'SEUe', 'SETLP', 'SEFIHPL', 'SEGRN']\n",
    "class_names = [name for name in class_names if name not in removed_labels]\n",
    "\n",
    "# Se crean X e Y\n",
    "X = df_unique_label.drop(columns=class_names, axis=1)\n",
    "y = df_unique_label[class_names].values\n",
    "\n",
    "# Se escala X\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Aplica PCA\n",
    "pca = PCA(n_components=25)  # Ajusta n_components según lo que necesites\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Se divide en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Se crea la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Se crea el modelo\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "\n",
    "# Hiper parametros\n",
    "mlp_params = {\n",
    "    'estimator__hidden_layer_sizes': [(50,)],  # Menos configuraciones de capas\n",
    "    'estimator__alpha': [0.0001]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "mlp_clf = OneVsRestClassifier(mlp_model)\n",
    "mlp_grid_search = GridSearchCV(mlp_clf, mlp_params, scoring=make_scorer(f1_score, average='micro', zero_division=0), cv=kf, n_jobs=-1, verbose=1)\n",
    "\n",
    "mlp_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Encontrar el mejor resultado\n",
    "mlp_best_model = mlp_grid_search.best_estimator_\n",
    "mlp_y_pred = mlp_best_model.predict(X_test)\n",
    "mlp_report = classification_report(y_test, mlp_y_pred, target_names=class_names, zero_division=0)\n",
    "\n",
    "print(\"MLP Classifier con PCA\")\n",
    "print(f\"Mejores hiperparámetros: {mlp_grid_search.best_params_}\")\n",
    "print(mlp_report)\n",
    "\n",
    "##################\n",
    "# Codigo para crear las curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(mlp_best_model, X_train, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "# Se calcula la media y la desv. estándar\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Se generan los graficos\n",
    "plt.figure()\n",
    "plt.title(\"Curva de Aprendizaje - MLP Classifier\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "# Se dibujan las rectas\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
